{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Get Datasets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df_raw = pd.read_csv(\"D:\\School\\ITC\\Y3\\Semet 1\\Intro DS\\Projects\\Diabetes-Classification\\selected_dataset\\DiaHealth A Bangladeshi Dataset for Type 2 Diabetes Prediction\\Cleaned_Datasets\\Diabetes_Final_Data_Cleaned_v3.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>systolic_bp</th>\n",
       "      <th>diastolic_bp</th>\n",
       "      <th>glucose</th>\n",
       "      <th>bmi</th>\n",
       "      <th>family_diabetes</th>\n",
       "      <th>hypertensive</th>\n",
       "      <th>diabetic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4725</th>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>146</td>\n",
       "      <td>77</td>\n",
       "      <td>9.42</td>\n",
       "      <td>18.35</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4726</th>\n",
       "      <td>74</td>\n",
       "      <td>1</td>\n",
       "      <td>164</td>\n",
       "      <td>89</td>\n",
       "      <td>6.47</td>\n",
       "      <td>24.99</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4727</th>\n",
       "      <td>75</td>\n",
       "      <td>1</td>\n",
       "      <td>141</td>\n",
       "      <td>104</td>\n",
       "      <td>8.31</td>\n",
       "      <td>22.75</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4728</th>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>139</td>\n",
       "      <td>80</td>\n",
       "      <td>4.90</td>\n",
       "      <td>17.87</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4729</th>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>134</td>\n",
       "      <td>93</td>\n",
       "      <td>5.15</td>\n",
       "      <td>30.92</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      age  gender  systolic_bp  diastolic_bp  glucose    bmi  family_diabetes  \\\n",
       "4725   70       1          146            77     9.42  18.35                0   \n",
       "4726   74       1          164            89     6.47  24.99                0   \n",
       "4727   75       1          141           104     8.31  22.75                0   \n",
       "4728   36       0          139            80     4.90  17.87                0   \n",
       "4729   26       0          134            93     5.15  30.92                0   \n",
       "\n",
       "      hypertensive  diabetic  \n",
       "4725             1         0  \n",
       "4726             1         0  \n",
       "4727             0         1  \n",
       "4728             0         0  \n",
       "4729             0         0  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df_raw.copy()\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **1. Linear-Based Models**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1.1. Logistic Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confustion Metrix: \n",
      "[[1136  239]\n",
      " [ 362  992]]\n",
      "Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.83      0.79      1375\n",
      "           1       0.81      0.73      0.77      1354\n",
      "\n",
      "    accuracy                           0.78      2729\n",
      "   macro avg       0.78      0.78      0.78      2729\n",
      "weighted avg       0.78      0.78      0.78      2729\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, PowerTransformer\n",
    "\n",
    "# get data\n",
    "X = df.drop(['diabetic'], axis=1)\n",
    "y = df['diabetic']\n",
    "\n",
    "# resample data\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X_resampled, y_resampled = ros.fit_resample(X, y)\n",
    "\n",
    "# split resampled data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_resampled,\n",
    "    y_resampled,\n",
    "    test_size=0.3,\n",
    "    random_state=42)\n",
    "\n",
    "# specify features to be scaled\n",
    "features_to_scale = ['age', 'systolic_bp', 'diastolic_bp', 'glucose', 'bmi']\n",
    "\n",
    "# Define the feature categories for scaling\n",
    "skewed_features = ['glucose', 'systolic_bp']\n",
    "outlier_features = ['diastolic_bp']\n",
    "normal_features = ['bmi', 'age']\n",
    "\n",
    "# Define the scaling transformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('power', PowerTransformer(method='yeo-johnson'), skewed_features),\n",
    "        ('robust', RobustScaler(), outlier_features),\n",
    "        ('standard', StandardScaler(), normal_features)\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "# Scale the data using the preprocessor\n",
    "X_train_scaled = preprocessor.fit_transform(X_train)\n",
    "X_test_scaled = preprocessor.transform(X_test)\n",
    "\n",
    "# train data\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# predict\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# evaluation\n",
    "print(\"Confustion Metrix: \")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"Classification Report: \")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Save the model and scaler obj**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import joblib\n",
    "\n",
    "# # Specify the directory path\n",
    "# save_dir = r\"D:\\School\\ITC\\Y3\\Semet 1\\Intro DS\\Projects\\Diabetes-Classification\\models\"\n",
    "\n",
    "# # Save the model and preprocessor\n",
    "# print(joblib.dump(model, os.path.join(save_dir, 'logistic_model.pkl')))\n",
    "# print(joblib.dump(preprocessor, os.path.join(save_dir, 'logistic_preprocessor.pkl')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load model to use**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes, he or she has diabetes\n"
     ]
    }
   ],
   "source": [
    "import joblib, os\n",
    "import pandas as pd\n",
    "\n",
    "# Specify the directory path\n",
    "save_dir = r\"D:\\School\\ITC\\Y3\\Semet 1\\Intro DS\\Projects\\Diabetes-Classification\\models\"\n",
    "\n",
    "# Load the model and preprocessor\n",
    "model = joblib.load(os.path.join(save_dir, 'logistic_model.pkl'))\n",
    "preprocessor = joblib.load(os.path.join(save_dir, 'logistic_preprocessor.pkl'))\n",
    "\n",
    "# New data to make predictions on\n",
    "X_new = pd.DataFrame(\n",
    "    {\n",
    "        'age': [70.00],\n",
    "        'gender': [0],\n",
    "        'systolic_bp': [146.00],\n",
    "        'diastolic_bp': [84.00],\n",
    "        'glucose': [9.51],\n",
    "        'bmi': [20.04],\n",
    "        'family_diabetes': [0],\n",
    "        'hypertensive': [0],\n",
    "    }\n",
    ")\n",
    "\n",
    "# Transform the new data using the preprocessor\n",
    "X_new_transformed = preprocessor.transform(X_new)\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(X_new_transformed)\n",
    "\n",
    "# print the result\n",
    "if predictions == 1:\n",
    "    print(\"Yes, he or she has diabetes\")\n",
    "else: \n",
    "    print(\"No, he or she doesn't has diabetes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1.2. LDA (LiDA: Linear Discriminant Analysis)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confustion Metrix: \n",
      "[[1171  204]\n",
      " [ 404  950]]\n",
      "Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.85      0.79      1375\n",
      "           1       0.82      0.70      0.76      1354\n",
      "\n",
      "    accuracy                           0.78      2729\n",
      "   macro avg       0.78      0.78      0.78      2729\n",
      "weighted avg       0.78      0.78      0.78      2729\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, PowerTransformer\n",
    "\n",
    "# get data\n",
    "X = df.drop(['diabetic'], axis=1)\n",
    "y = df['diabetic']\n",
    "\n",
    "# resample data\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X_resampled, y_resampled = ros.fit_resample(X, y)\n",
    "\n",
    "# split resampled data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_resampled,\n",
    "    y_resampled,\n",
    "    test_size=0.3,\n",
    "    random_state=42)\n",
    "\n",
    "# specify features to be scaled\n",
    "features_to_scale = ['age', 'systolic_bp', 'diastolic_bp', 'glucose', 'bmi']\n",
    "\n",
    "# Define the feature categories for scaling\n",
    "skewed_features = ['glucose', 'systolic_bp']\n",
    "outlier_features = ['diastolic_bp']\n",
    "normal_features = ['bmi', 'age']\n",
    "\n",
    "# Define the scaling transformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('power', PowerTransformer(method='yeo-johnson'), skewed_features),\n",
    "        ('robust', RobustScaler(), outlier_features),\n",
    "        ('standard', StandardScaler(), normal_features)\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "# Scale the data using the preprocessor\n",
    "X_train_scaled = preprocessor.fit_transform(X_train)\n",
    "X_test_scaled = preprocessor.transform(X_test)\n",
    "\n",
    "# train data\n",
    "model = LinearDiscriminantAnalysis()\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# predict\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# evaluation\n",
    "print(\"Confustion Metrix: \")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"Classification Report: \")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1.3. SVM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confustion Metrix: \n",
      "[[1172  203]\n",
      " [ 222 1132]]\n",
      "Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.85      0.85      1375\n",
      "           1       0.85      0.84      0.84      1354\n",
      "\n",
      "    accuracy                           0.84      2729\n",
      "   macro avg       0.84      0.84      0.84      2729\n",
      "weighted avg       0.84      0.84      0.84      2729\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, PowerTransformer\n",
    "\n",
    "# get data\n",
    "X = df.drop(['diabetic'], axis=1)\n",
    "y = df['diabetic']\n",
    "\n",
    "# resample data\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X_resampled, y_resampled = ros.fit_resample(X, y)\n",
    "\n",
    "# split resampled data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_resampled,\n",
    "    y_resampled,\n",
    "    test_size=0.3,\n",
    "    random_state=42)\n",
    "\n",
    "# specify features to be scaled\n",
    "features_to_scale = ['age', 'systolic_bp', 'diastolic_bp', 'glucose', 'bmi']\n",
    "\n",
    "# Define the feature categories for scaling\n",
    "skewed_features = ['glucose', 'systolic_bp']\n",
    "outlier_features = ['diastolic_bp']\n",
    "normal_features = ['bmi', 'age']\n",
    "\n",
    "# Define the scaling transformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('power', PowerTransformer(method='yeo-johnson'), skewed_features),\n",
    "        ('robust', RobustScaler(), outlier_features),\n",
    "        ('standard', StandardScaler(), normal_features)\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "# Scale the data using the preprocessor\n",
    "X_train_scaled = preprocessor.fit_transform(X_train)\n",
    "X_test_scaled = preprocessor.transform(X_test)\n",
    "\n",
    "# train data\n",
    "model = SVC()\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# predict\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# evaluation\n",
    "print(\"Confustion Metrix: \")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"Classification Report: \")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **2. Tree-Based Models**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2.1. Decision Trees**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Oversampling: `imblearn.over_sampling.RandomOverSampler`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confustion Metrix: \n",
      "[[1304   71]\n",
      " [   0 1354]]\n",
      "Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.95      0.97      1375\n",
      "           1       0.95      1.00      0.97      1354\n",
      "\n",
      "    accuracy                           0.97      2729\n",
      "   macro avg       0.98      0.97      0.97      2729\n",
      "weighted avg       0.98      0.97      0.97      2729\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# data\n",
    "X = df.drop('diabetic', axis=1)\n",
    "y = df['diabetic']\n",
    "\n",
    "# Resample the data\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X_resampled, y_resampled = ros.fit_resample(X, y)\n",
    "\n",
    "# Split the resampled data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_resampled,\n",
    "    y_resampled,\n",
    "    test_size=0.3,\n",
    "    random_state=42)\n",
    "\n",
    "# Train the model\n",
    "model = DecisionTreeClassifier(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(\"Confustion Metrix: \")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"Classification Report: \")\n",
    "print(classification_report( y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hybrid Method: `imblearn.combine.SMOTEENN`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confustion Metrix: \n",
      "[[ 945  120]\n",
      " [  63 1220]]\n",
      "Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.89      0.91      1065\n",
      "           1       0.91      0.95      0.93      1283\n",
      "\n",
      "    accuracy                           0.92      2348\n",
      "   macro avg       0.92      0.92      0.92      2348\n",
      "weighted avg       0.92      0.92      0.92      2348\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from imblearn.combine import SMOTEENN\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# data\n",
    "X = df.drop('diabetic', axis=1)\n",
    "y = df['diabetic']\n",
    "\n",
    "# Combine SMOTE with ENN\n",
    "smote_enn = SMOTEENN(random_state=0)\n",
    "X_resampled, y_resampled = smote_enn.fit_resample(X, y)\n",
    "\n",
    "# Split the resampled data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.3, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "model = DecisionTreeClassifier(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(\"Confustion Metrix: \")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"Classification Report: \")\n",
    "print(classification_report( y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hybrid Method: `imblearn.combine.SMOTETomek`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confustion Metrix: \n",
      "[[1187  197]\n",
      " [  92 1238]]\n",
      "Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.86      0.89      1384\n",
      "           1       0.86      0.93      0.90      1330\n",
      "\n",
      "    accuracy                           0.89      2714\n",
      "   macro avg       0.90      0.89      0.89      2714\n",
      "weighted avg       0.90      0.89      0.89      2714\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from imblearn.combine import SMOTETomek\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# data\n",
    "X = df.drop('diabetic', axis=1)\n",
    "y = df['diabetic']\n",
    "\n",
    "# Combine SMOTE with Tomek\n",
    "smote_tomek = SMOTETomek(random_state=0)\n",
    "X_resampled, y_resampled = smote_tomek.fit_resample(X, y)\n",
    "\n",
    "# Split the resampled data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.3, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "model = DecisionTreeClassifier(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(\"Confustion Metrix: \")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"Classification Report: \")\n",
    "print(classification_report( y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2.2. Random Forest (ព្រៃអាគមន៍)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Oversampling: `imblearn.over_sampling.RandomOverSampler` (YK)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  RandomForestClassifier\n",
      "Confustion Metrix: \n",
      "[[1356   19]\n",
      " [   0 1354]]\n",
      "Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99      1375\n",
      "           1       0.99      1.00      0.99      1354\n",
      "\n",
      "    accuracy                           0.99      2729\n",
      "   macro avg       0.99      0.99      0.99      2729\n",
      "weighted avg       0.99      0.99      0.99      2729\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# data\n",
    "X = df.drop('diabetic', axis=1)\n",
    "y = df['diabetic']\n",
    "\n",
    "# Resample the data\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X_resampled, y_resampled = ros.fit_resample(X, y)\n",
    "\n",
    "# Split the resampled data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_resampled,\n",
    "    y_resampled,\n",
    "    test_size=0.3,\n",
    "    random_state=42)\n",
    "\n",
    "# Train the model\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(\"Model: \", type(model).__name__)\n",
    "print(\"Confustion Metrix: \")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"Classification Report: \")\n",
    "print(classification_report( y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Oversampling: `imblearn.combine.SMOTEENN`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confustion Metrix: \n",
      "[[ 997   68]\n",
      " [  21 1262]]\n",
      "Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.94      0.96      1065\n",
      "           1       0.95      0.98      0.97      1283\n",
      "\n",
      "    accuracy                           0.96      2348\n",
      "   macro avg       0.96      0.96      0.96      2348\n",
      "weighted avg       0.96      0.96      0.96      2348\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from imblearn.combine import SMOTEENN\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# data\n",
    "X = df.drop('diabetic', axis=1)\n",
    "y = df['diabetic']\n",
    "\n",
    "# Combine SMOTE with ENN\n",
    "smote_enn = SMOTEENN(random_state=0)\n",
    "X_resampled, y_resampled = smote_enn.fit_resample(X, y)\n",
    "\n",
    "# Split the resampled data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.3, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(\"Confustion Metrix: \")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"Classification Report: \")\n",
    "print(classification_report( y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Oversampling: `imblearn.combine.SMOTETomek`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confustion Metrix: \n",
      "[[1242  142]\n",
      " [  42 1288]]\n",
      "Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.90      0.93      1384\n",
      "           1       0.90      0.97      0.93      1330\n",
      "\n",
      "    accuracy                           0.93      2714\n",
      "   macro avg       0.93      0.93      0.93      2714\n",
      "weighted avg       0.93      0.93      0.93      2714\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from imblearn.combine import SMOTETomek\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# data\n",
    "X = df.drop('diabetic', axis=1)\n",
    "y = df['diabetic']\n",
    "\n",
    "# Combine SMOTE with Tomek\n",
    "smote_tomek = SMOTETomek(random_state=0)\n",
    "X_resampled, y_resampled = smote_tomek.fit_resample(X, y)\n",
    "\n",
    "# Split the resampled data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.3, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(\"Confustion Metrix: \")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"Classification Report: \")\n",
    "print(classification_report( y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2.3. Gradient Boosting Machines (GBM)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Oversampling: `imblearn.over_sampling.RandomOverSampler`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      "[[1197  178]\n",
      " [ 135 1219]]\n",
      "Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.87      0.88      1375\n",
      "           1       0.87      0.90      0.89      1354\n",
      "\n",
      "    accuracy                           0.89      2729\n",
      "   macro avg       0.89      0.89      0.89      2729\n",
      "weighted avg       0.89      0.89      0.89      2729\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# data\n",
    "X = df.drop('diabetic', axis=1)\n",
    "y = df['diabetic']\n",
    "\n",
    "# Combine SMOTE with Tomek\n",
    "ros = RandomOverSampler(random_state=0)\n",
    "X_resampled, y_resampled = ros.fit_resample(X, y)\n",
    "\n",
    "# Split the resampled data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.3, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "model = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(\"Confusion Matrix: \")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"Classification Report: \")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2.4. XGBoost**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Oversampling: `imblearn.over_sampling.RandomOverSampler`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      "[[1339   36]\n",
      " [   0 1354]]\n",
      "Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.99      1375\n",
      "           1       0.97      1.00      0.99      1354\n",
      "\n",
      "    accuracy                           0.99      2729\n",
      "   macro avg       0.99      0.99      0.99      2729\n",
      "weighted avg       0.99      0.99      0.99      2729\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# data\n",
    "X = df.drop('diabetic', axis=1)\n",
    "y = df['diabetic']\n",
    "\n",
    "# Combine SMOTE with Tomek\n",
    "ros = RandomOverSampler(random_state=0)\n",
    "X_resampled, y_resampled = ros.fit_resample(X, y)\n",
    "\n",
    "# Split the resampled data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.3, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "model = XGBClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(\"Confusion Matrix: \")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"Classification Report: \")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2.5. LightGBM**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Oversampling: `imblearn.over_sampling.RandomOverSampler`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 3194, number of negative: 3173\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000559 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 735\n",
      "[LightGBM] [Info] Number of data points in the train set: 6367, number of used features: 8\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.501649 -> initscore=0.006597\n",
      "[LightGBM] [Info] Start training from score 0.006597\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "import lightgbm as lgb\n",
    "\n",
    "# data\n",
    "X = df.drop('diabetic', axis=1)\n",
    "y = df['diabetic']\n",
    "\n",
    "# Combine SMOTE with Tomek\n",
    "ros = RandomOverSampler(random_state=0)\n",
    "X_resampled, y_resampled = ros.fit_resample(X, y)\n",
    "\n",
    "# Split the resampled data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.3, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "train_data = lgb.Dataset(X_train, label=y_train)\n",
    "params = {'objective': 'binary', 'metric': 'auc', 'boosting_type': 'gbdt', 'num_leaves': 31, 'learning_rate': 0.05}\n",
    "model = lgb.train(\n",
    "    params, \n",
    "    train_data, 100)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      "[[1283   92]\n",
      " [   0 1354]]\n",
      "Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.93      0.97      1375\n",
      "           1       0.94      1.00      0.97      1354\n",
      "\n",
      "    accuracy                           0.97      2729\n",
      "   macro avg       0.97      0.97      0.97      2729\n",
      "weighted avg       0.97      0.97      0.97      2729\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print evaluation metrics\n",
    "print(\"Confusion Matrix: \")\n",
    "print(confusion_matrix(y_test, (y_pred > 0.5).astype(int)))\n",
    "print(\"Classification Report: \")\n",
    "print(classification_report(y_test, (y_pred > 0.5).astype(int)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2.5. CatBoost**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Oversampling: `imblearn.over_sampling.RandomOverSampler`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.187592\n",
      "0:\tlearn: 0.6307334\ttotal: 1.67ms\tremaining: 165ms\n",
      "1:\tlearn: 0.5824462\ttotal: 3.04ms\tremaining: 149ms\n",
      "2:\tlearn: 0.5476780\ttotal: 4.63ms\tremaining: 150ms\n",
      "3:\tlearn: 0.5194200\ttotal: 6.15ms\tremaining: 148ms\n",
      "4:\tlearn: 0.5005798\ttotal: 7.49ms\tremaining: 142ms\n",
      "5:\tlearn: 0.4809404\ttotal: 8.93ms\tremaining: 140ms\n",
      "6:\tlearn: 0.4624360\ttotal: 10.5ms\tremaining: 139ms\n",
      "7:\tlearn: 0.4523346\ttotal: 12ms\tremaining: 138ms\n",
      "8:\tlearn: 0.4402018\ttotal: 13.4ms\tremaining: 136ms\n",
      "9:\tlearn: 0.4310513\ttotal: 14.9ms\tremaining: 134ms\n",
      "10:\tlearn: 0.4213062\ttotal: 16.3ms\tremaining: 132ms\n",
      "11:\tlearn: 0.4140643\ttotal: 17.9ms\tremaining: 132ms\n",
      "12:\tlearn: 0.4076326\ttotal: 19.7ms\tremaining: 132ms\n",
      "13:\tlearn: 0.4006168\ttotal: 21.3ms\tremaining: 131ms\n",
      "14:\tlearn: 0.3917853\ttotal: 22.7ms\tremaining: 129ms\n",
      "15:\tlearn: 0.3867005\ttotal: 24.5ms\tremaining: 129ms\n",
      "16:\tlearn: 0.3829175\ttotal: 26.1ms\tremaining: 128ms\n",
      "17:\tlearn: 0.3780145\ttotal: 27.7ms\tremaining: 126ms\n",
      "18:\tlearn: 0.3705604\ttotal: 29.6ms\tremaining: 126ms\n",
      "19:\tlearn: 0.3658402\ttotal: 31.5ms\tremaining: 126ms\n",
      "20:\tlearn: 0.3628742\ttotal: 33ms\tremaining: 124ms\n",
      "21:\tlearn: 0.3596044\ttotal: 34.5ms\tremaining: 122ms\n",
      "22:\tlearn: 0.3571242\ttotal: 36ms\tremaining: 120ms\n",
      "23:\tlearn: 0.3518165\ttotal: 37.6ms\tremaining: 119ms\n",
      "24:\tlearn: 0.3471483\ttotal: 39.3ms\tremaining: 118ms\n",
      "25:\tlearn: 0.3407457\ttotal: 40.8ms\tremaining: 116ms\n",
      "26:\tlearn: 0.3351893\ttotal: 42.9ms\tremaining: 116ms\n",
      "27:\tlearn: 0.3297564\ttotal: 44.5ms\tremaining: 114ms\n",
      "28:\tlearn: 0.3260012\ttotal: 46ms\tremaining: 113ms\n",
      "29:\tlearn: 0.3211917\ttotal: 47.5ms\tremaining: 111ms\n",
      "30:\tlearn: 0.3145277\ttotal: 48.9ms\tremaining: 109ms\n",
      "31:\tlearn: 0.3101123\ttotal: 50.7ms\tremaining: 108ms\n",
      "32:\tlearn: 0.3064152\ttotal: 52.2ms\tremaining: 106ms\n",
      "33:\tlearn: 0.3035738\ttotal: 53.8ms\tremaining: 104ms\n",
      "34:\tlearn: 0.3001289\ttotal: 55.2ms\tremaining: 103ms\n",
      "35:\tlearn: 0.2958645\ttotal: 56.7ms\tremaining: 101ms\n",
      "36:\tlearn: 0.2932646\ttotal: 58.5ms\tremaining: 99.5ms\n",
      "37:\tlearn: 0.2912885\ttotal: 59.9ms\tremaining: 97.7ms\n",
      "38:\tlearn: 0.2886775\ttotal: 61.3ms\tremaining: 95.8ms\n",
      "39:\tlearn: 0.2864784\ttotal: 62.8ms\tremaining: 94.2ms\n",
      "40:\tlearn: 0.2833912\ttotal: 64.5ms\tremaining: 92.9ms\n",
      "41:\tlearn: 0.2813281\ttotal: 65.9ms\tremaining: 91ms\n",
      "42:\tlearn: 0.2772100\ttotal: 67.3ms\tremaining: 89.3ms\n",
      "43:\tlearn: 0.2748975\ttotal: 69ms\tremaining: 87.8ms\n",
      "44:\tlearn: 0.2724411\ttotal: 70.7ms\tremaining: 86.5ms\n",
      "45:\tlearn: 0.2706828\ttotal: 72.3ms\tremaining: 84.9ms\n",
      "46:\tlearn: 0.2681324\ttotal: 73.9ms\tremaining: 83.4ms\n",
      "47:\tlearn: 0.2648897\ttotal: 75.7ms\tremaining: 82ms\n",
      "48:\tlearn: 0.2615421\ttotal: 77.7ms\tremaining: 80.8ms\n",
      "49:\tlearn: 0.2588339\ttotal: 79.4ms\tremaining: 79.4ms\n",
      "50:\tlearn: 0.2573692\ttotal: 81ms\tremaining: 77.8ms\n",
      "51:\tlearn: 0.2554754\ttotal: 83.3ms\tremaining: 76.9ms\n",
      "52:\tlearn: 0.2517182\ttotal: 85.5ms\tremaining: 75.8ms\n",
      "53:\tlearn: 0.2501150\ttotal: 87ms\tremaining: 74.1ms\n",
      "54:\tlearn: 0.2477163\ttotal: 88.4ms\tremaining: 72.3ms\n",
      "55:\tlearn: 0.2457728\ttotal: 90.2ms\tremaining: 70.9ms\n",
      "56:\tlearn: 0.2431754\ttotal: 92.2ms\tremaining: 69.5ms\n",
      "57:\tlearn: 0.2411641\ttotal: 93.6ms\tremaining: 67.7ms\n",
      "58:\tlearn: 0.2387752\ttotal: 95.1ms\tremaining: 66.1ms\n",
      "59:\tlearn: 0.2371716\ttotal: 96.8ms\tremaining: 64.5ms\n",
      "60:\tlearn: 0.2343036\ttotal: 98.7ms\tremaining: 63.1ms\n",
      "61:\tlearn: 0.2324006\ttotal: 100ms\tremaining: 61.4ms\n",
      "62:\tlearn: 0.2293034\ttotal: 102ms\tremaining: 59.7ms\n",
      "63:\tlearn: 0.2266060\ttotal: 103ms\tremaining: 58.1ms\n",
      "64:\tlearn: 0.2248829\ttotal: 105ms\tremaining: 56.6ms\n",
      "65:\tlearn: 0.2231092\ttotal: 107ms\tremaining: 54.9ms\n",
      "66:\tlearn: 0.2215860\ttotal: 108ms\tremaining: 53.3ms\n",
      "67:\tlearn: 0.2200320\ttotal: 110ms\tremaining: 51.7ms\n",
      "68:\tlearn: 0.2173192\ttotal: 112ms\tremaining: 50.2ms\n",
      "69:\tlearn: 0.2158117\ttotal: 113ms\tremaining: 48.6ms\n",
      "70:\tlearn: 0.2144784\ttotal: 115ms\tremaining: 47ms\n",
      "71:\tlearn: 0.2112222\ttotal: 117ms\tremaining: 45.5ms\n",
      "72:\tlearn: 0.2105271\ttotal: 118ms\tremaining: 43.8ms\n",
      "73:\tlearn: 0.2086271\ttotal: 120ms\tremaining: 42.3ms\n",
      "74:\tlearn: 0.2072134\ttotal: 122ms\tremaining: 40.7ms\n",
      "75:\tlearn: 0.2060121\ttotal: 124ms\tremaining: 39.1ms\n",
      "76:\tlearn: 0.2043091\ttotal: 126ms\tremaining: 37.5ms\n",
      "77:\tlearn: 0.2024383\ttotal: 127ms\tremaining: 35.8ms\n",
      "78:\tlearn: 0.2014824\ttotal: 129ms\tremaining: 34.2ms\n",
      "79:\tlearn: 0.2002113\ttotal: 131ms\tremaining: 32.6ms\n",
      "80:\tlearn: 0.1978758\ttotal: 132ms\tremaining: 31ms\n",
      "81:\tlearn: 0.1966261\ttotal: 133ms\tremaining: 29.3ms\n",
      "82:\tlearn: 0.1956985\ttotal: 135ms\tremaining: 27.6ms\n",
      "83:\tlearn: 0.1947154\ttotal: 137ms\tremaining: 26.1ms\n",
      "84:\tlearn: 0.1939790\ttotal: 138ms\tremaining: 24.4ms\n",
      "85:\tlearn: 0.1920405\ttotal: 140ms\tremaining: 22.8ms\n",
      "86:\tlearn: 0.1911220\ttotal: 141ms\tremaining: 21.1ms\n",
      "87:\tlearn: 0.1889339\ttotal: 143ms\tremaining: 19.5ms\n",
      "88:\tlearn: 0.1872334\ttotal: 144ms\tremaining: 17.9ms\n",
      "89:\tlearn: 0.1852979\ttotal: 146ms\tremaining: 16.2ms\n",
      "90:\tlearn: 0.1839757\ttotal: 148ms\tremaining: 14.6ms\n",
      "91:\tlearn: 0.1823202\ttotal: 149ms\tremaining: 13ms\n",
      "92:\tlearn: 0.1802947\ttotal: 151ms\tremaining: 11.4ms\n",
      "93:\tlearn: 0.1791539\ttotal: 153ms\tremaining: 9.74ms\n",
      "94:\tlearn: 0.1774392\ttotal: 154ms\tremaining: 8.12ms\n",
      "95:\tlearn: 0.1767116\ttotal: 156ms\tremaining: 6.5ms\n",
      "96:\tlearn: 0.1748887\ttotal: 158ms\tremaining: 4.88ms\n",
      "97:\tlearn: 0.1739738\ttotal: 159ms\tremaining: 3.25ms\n",
      "98:\tlearn: 0.1724733\ttotal: 161ms\tremaining: 1.63ms\n",
      "99:\tlearn: 0.1718060\ttotal: 163ms\tremaining: 0us\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x137e3ac0e90>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# data\n",
    "X = df.drop('diabetic', axis=1)\n",
    "y = df['diabetic']\n",
    "\n",
    "# Resample the data\n",
    "ros = RandomOverSampler(random_state=0)\n",
    "X_resampled, y_resampled = ros.fit_resample(X, y)\n",
    "\n",
    "# Split the resampled data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.3, random_state=42)\n",
    "\n",
    "# Train the CatBoost model\n",
    "model = CatBoostClassifier(iterations=100,\n",
    "                        #    learning_rate=0.1, \n",
    "                        #    depth=10, \n",
    "                           random_state=42)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  CatBoostClassifier\n",
      "Confusion Matrix: \n",
      "[[1262  113]\n",
      " [   8 1346]]\n",
      "Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.92      0.95      1375\n",
      "           1       0.92      0.99      0.96      1354\n",
      "\n",
      "    accuracy                           0.96      2729\n",
      "   macro avg       0.96      0.96      0.96      2729\n",
      "weighted avg       0.96      0.96      0.96      2729\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(\"Model: \", type(model).__name__)\n",
    "print(\"Confusion Matrix: \")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"Classification Report: \")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **3. Probabilistic Models**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3.1. Naive Bayes: Gaussian Naive Bayes (Gusion)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      "[[1068  307]\n",
      " [ 317 1037]]\n",
      "Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.78      0.77      1375\n",
      "           1       0.77      0.77      0.77      1354\n",
      "\n",
      "    accuracy                           0.77      2729\n",
      "   macro avg       0.77      0.77      0.77      2729\n",
      "weighted avg       0.77      0.77      0.77      2729\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# data\n",
    "X = df.drop('diabetic', axis=1)\n",
    "y = df['diabetic']\n",
    "\n",
    "# Resample the data\n",
    "ros = RandomOverSampler(random_state=0)\n",
    "X_resampled, y_resampled = ros.fit_resample(X, y)\n",
    "\n",
    "# Split the resampled data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.3, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "model = GaussianNB()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(\"Confusion Matrix: \")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"Classification Report: \")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3.2. Naive Bayes: Multinomial Naive Bayes (Milk Tea No Moew)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      "[[1015  360]\n",
      " [ 567  787]]\n",
      "Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.74      0.69      1375\n",
      "           1       0.69      0.58      0.63      1354\n",
      "\n",
      "    accuracy                           0.66      2729\n",
      "   macro avg       0.66      0.66      0.66      2729\n",
      "weighted avg       0.66      0.66      0.66      2729\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# data\n",
    "X = df.drop('diabetic', axis=1)\n",
    "y = df['diabetic']\n",
    "\n",
    "# Resample the data\n",
    "ros = RandomOverSampler(random_state=0)\n",
    "X_resampled, y_resampled = ros.fit_resample(X, y)\n",
    "\n",
    "# Split the resampled data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.3, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "model = MultinomialNB()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(\"Confusion Matrix: \")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"Classification Report: \")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3.3. Naive Bayes: Bernoulli Naive Bayes (Burn Luo Yi)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      "[[840  78]\n",
      " [467 435]]\n",
      "Classification Report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.92      0.76       918\n",
      "           1       0.85      0.48      0.61       902\n",
      "\n",
      "    accuracy                           0.70      1820\n",
      "   macro avg       0.75      0.70      0.68      1820\n",
      "weighted avg       0.74      0.70      0.69      1820\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# data\n",
    "X = df.drop('diabetic', axis=1)\n",
    "y = df['diabetic']\n",
    "\n",
    "# Resample the data\n",
    "ros = RandomOverSampler(random_state=0)\n",
    "X_resampled, y_resampled = ros.fit_resample(X, y)\n",
    "\n",
    "# Split the resampled data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "model = BernoulliNB()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(\"Confusion Matrix: \")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"Classification Report: \")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
